{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Question 0: Create a DataFrame with three rows and four columns. Name the\n",
        "# columns 'Col1', 'Col2', 'Col3', 'Col4'. Create an index for the DataFrame\n",
        "# and give the rows the index values of 'Row1', 'Row2', 'Row3'. Place a value\n",
        "# in each column equal to the {ColumnName/RowName}. e.g. Col1/Row1. Print\n",
        "# the entire DataFrame.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3'])\n",
        "\n",
        "for col in df:\n",
        "  for i, value in df[col].items():\n",
        "    df.at[i, col] = f'{i}/{col}'\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "OYXzAuLwqAqn",
        "outputId": "9dc75568-f3ea-4732-aea8-5305a46041c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Col1       Col2       Col3       Col4\n",
              "Row1  Row1/Col1  Row1/Col2  Row1/Col3  Row1/Col4\n",
              "Row2  Row2/Col1  Row2/Col2  Row2/Col3  Row2/Col4\n",
              "Row3  Row3/Col1  Row3/Col2  Row3/Col3  Row3/Col4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0366e05-f3f2-4feb-ac7b-fb2934c0b94c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col1</th>\n",
              "      <th>Col2</th>\n",
              "      <th>Col3</th>\n",
              "      <th>Col4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>Row1/Col1</td>\n",
              "      <td>Row1/Col2</td>\n",
              "      <td>Row1/Col3</td>\n",
              "      <td>Row1/Col4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>Row2/Col1</td>\n",
              "      <td>Row2/Col2</td>\n",
              "      <td>Row2/Col3</td>\n",
              "      <td>Row2/Col4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>Row3/Col1</td>\n",
              "      <td>Row3/Col2</td>\n",
              "      <td>Row3/Col3</td>\n",
              "      <td>Row3/Col4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0366e05-f3f2-4feb-ac7b-fb2934c0b94c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0366e05-f3f2-4feb-ac7b-fb2934c0b94c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0366e05-f3f2-4feb-ac7b-fb2934c0b94c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f34816b9-629d-4db7-978d-76b1475d927f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f34816b9-629d-4db7-978d-76b1475d927f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f34816b9-629d-4db7-978d-76b1475d927f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c848e5bb-69a3-4705-a779-b7dc8a16ef8e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c848e5bb-69a3-4705-a779-b7dc8a16ef8e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Col1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Row1/Col1\",\n          \"Row2/Col1\",\n          \"Row3/Col1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Col2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Row1/Col2\",\n          \"Row2/Col2\",\n          \"Row3/Col2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Col3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Row1/Col3\",\n          \"Row2/Col3\",\n          \"Row3/Col3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Col4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Row1/Col4\",\n          \"Row2/Col4\",\n          \"Row3/Col4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These first 15 questions are part of the Week 3 Apply Assignment. Question 16 to the end (Question 27) represents the Week 3 Team Assignment. Therefore, once you finish through Question 15, submit this file (even with the remaining questions blank) for your Week 3 Apply Assignment.\n",
        "\n",
        "Then, for the Week 3 Team Assignment, continue working on this file in your assigned team to complete Questions 16-27. Collaborate with each other to determine the best way to solve each question task. You are welcome to modify your code (if you choose) for Questions 1-15 for the team assignment since you would have already submitted the Week 3 Apply Assignment.\n",
        "## **Data Import**"
      ],
      "metadata": {
        "id": "FyoTEKwkqUWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: Import the data file posted along with this assignment called\n",
        "# 'student_enrollment_sample.csv'. This file contains hypothetical data about\n",
        "# students enrolled in an online university. This university wants to help\n",
        "# their students succeed. However, many of them drop out for a variety of\n",
        "# reasons. Some feel hopeless, helpless, or lost. The university wants to\n",
        "# identify those students who are currently active, but likely to drop in\n",
        "# the near future so that they can intervene and get the them additional help.\n",
        "# Your task is to create a predictive model to classify those students who are\n",
        "# predicted to drop, but currently active to give to the advisement center for\n",
        "# targeted interventions. Complete the steps as outlined in the questions to\n",
        "# complete this task.\n",
        "\n",
        "# First, print out the first five records of the dataset. How many students are\n",
        "# in this sample?\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Import the data file\n",
        "df = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "\n",
        "# 2. Print the first five records\n",
        "print(\"First five records:\")\n",
        "print(df.head())\n",
        "\n",
        "# 3. Count the number of students\n",
        "num_students = df.shape[0]\n",
        "print(f\"\\nTotal number of students: {num_students}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyrqhSG-qa4w",
        "outputId": "ef847a9c-85d0-43b3-e993-e4accb769649"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five records:\n",
            "  EXPECTED_START_DATE GRADUATION_DATE  ENROLL_COUNT  NUMBER_AVERAGE  \\\n",
            "0                 NaN             NaN           1.0             0.0   \n",
            "1                 NaN        2/8/2016           1.0             0.0   \n",
            "2                 NaN             NaN           1.0             0.0   \n",
            "3                 NaN             NaN           1.0             0.0   \n",
            "4                 NaN             NaN           1.0             0.0   \n",
            "\n",
            "   MINUTES_ATTENDED  HOURS_ATTEMPTED  HOURS_EARNED  AR_BALANCE_AMOUNT  \\\n",
            "0               NaN              0.0           0.0                0.0   \n",
            "1               NaN              0.0           0.0                0.0   \n",
            "2               NaN              0.0           0.0                0.0   \n",
            "3               NaN              0.0           0.0                0.0   \n",
            "4               NaN              0.0           0.0                0.0   \n",
            "\n",
            "   MINUTES_ABSENT  DAYS_ABSENT  ...  CREDITS_LEFT  ENROLLMENT_COUNT  \\\n",
            "0             NaN          0.0  ...           NaN               NaN   \n",
            "1             NaN          0.0  ...           NaN               NaN   \n",
            "2             NaN          0.0  ...         180.0               2.0   \n",
            "3             NaN          0.0  ...          60.0               3.0   \n",
            "4             NaN          0.0  ...           NaN               NaN   \n",
            "\n",
            "  MODS_ATTENDED_COUNT HS_GRADUATED_FLAG DISABLED_FLAG  HISPANIC_FLAG  \\\n",
            "0                 NaN               NaN           NaN            NaN   \n",
            "1                 NaN               NaN           NaN            NaN   \n",
            "2                 0.0               0.0           0.0            0.0   \n",
            "3                 0.0               0.0           0.0            1.0   \n",
            "4                 NaN               NaN           NaN            NaN   \n",
            "\n",
            "   VETERAN_FLAG               STATUS_DESCRIPTION  IN_SCHOOL_FLAG  \\\n",
            "0           NaN            Application Cancelled             0.0   \n",
            "1           NaN                        Applicant             0.0   \n",
            "2           0.0  Pending Applicant - Portal Only             0.0   \n",
            "3           0.0                        Applicant             0.0   \n",
            "4           NaN  Pending Applicant - Portal Only             0.0   \n",
            "\n",
            "   SIMPLE_STATUS_DESCRIPTION  \n",
            "0                      Other  \n",
            "1                      Other  \n",
            "2                      Other  \n",
            "3                      Other  \n",
            "4                      Other  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "\n",
            "Total number of students: 50001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: Print out a list of missing values for each column in the\n",
        "# dataset. HINT: search for 'pandas .isna() example'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Import the data file\n",
        "try:\n",
        "    data = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: '/content/student_enrollment_sample-Laurie_Bagley.csv' not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# Calculate the sum of missing values for each column\n",
        "missing_values = data.isna().sum()\n",
        "\n",
        "# Print the list of missing values\n",
        "print(\"Missing values for each column in the dataset:\")\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "id": "LmqR7NVjqoKl",
        "outputId": "1cd131d5-50a8-44a3-e26e-c1f1515172da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values for each column in the dataset:\n",
            "EXPECTED_START_DATE           1871\n",
            "GRADUATION_DATE               1598\n",
            "ENROLL_COUNT                     1\n",
            "NUMBER_AVERAGE                   1\n",
            "MINUTES_ATTENDED             16287\n",
            "HOURS_ATTEMPTED                  1\n",
            "HOURS_EARNED                     1\n",
            "AR_BALANCE_AMOUNT                1\n",
            "MINUTES_ABSENT               16297\n",
            "DAYS_ABSENT                      1\n",
            "MINUTES_MAKEUP               16297\n",
            "REENTRY_NUMBER                   1\n",
            "PROGRAM_GROUP                   14\n",
            "BIRTH_DATE                    1361\n",
            "LAST_ACTIVITY_DATE            4388\n",
            "MOD_NUMBER                    1324\n",
            "COHORT_YEAR                   1375\n",
            "CUMMULATIVE_GPA              15550\n",
            "CUMMULATIVE_GPA_POINTS       37157\n",
            "CUMMULATIVE_GPA_CREDITS      37157\n",
            "AR_BALANCE                    1323\n",
            "ENROLLMENT_GPA                1322\n",
            "CREDITS_ATTEMPTED             1323\n",
            "CREDITS_EARNED                1323\n",
            "CREDITS_REQUIRED              1336\n",
            "CREDITS_LEFT                  1336\n",
            "ENROLLMENT_COUNT              1323\n",
            "MODS_ATTENDED_COUNT           1323\n",
            "HS_GRADUATED_FLAG             1323\n",
            "DISABLED_FLAG                 1323\n",
            "HISPANIC_FLAG                 1323\n",
            "VETERAN_FLAG                  1323\n",
            "STATUS_DESCRIPTION               1\n",
            "IN_SCHOOL_FLAG                   1\n",
            "SIMPLE_STATUS_DESCRIPTION        1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Make a copy of the original DataFrame to work with\n",
        "# (in case we want to use the original again later). Iterate through\n",
        "# the new DataFrame and remove any column that has more than 30% of\n",
        "# the records/cases missing. Print out a summary of missing value\n",
        "# percentages for each remaining column.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def process_enrollment_data(file_path, missing_threshold=0.30):\n",
        "    \"\"\"\n",
        "    Loads a CSV file, removes columns with more than the specified missing\n",
        "    value percentage, and prints a summary of missing values for remaining columns.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the 'student_enrollment_sample.csv' file.\n",
        "        missing_threshold (float): The threshold for missing data percentage\n",
        "                                   (e.g., 0.30 for 30%).\n",
        "    \"\"\"\n",
        "    # Load the data file\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        print(\"Please ensure the file is in the correct directory or provide the full path.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Calculate missing value percentages for all columns\n",
        "    missing_percentages = (df.isnull().sum() / len(df))\n",
        "\n",
        "    # Identify columns to drop (those with more than the threshold missing)\n",
        "    columns_to_drop = missing_percentages[missing_percentages > missing_threshold].index\n",
        "\n",
        "    print(f\"Original shape of the DataFrame: {df.shape}\")\n",
        "    print(f\"Number of columns to drop (>{missing_threshold*100}% missing): {len(columns_to_drop)}\")\n",
        "    print(f\"Dropped columns: {list(columns_to_drop)}\\n\")\n",
        "\n",
        "    # Drop the identified columns\n",
        "    # A loop is used here as requested in the prompt, although pandas allows direct dropping\n",
        "    for col in columns_to_drop:\n",
        "        if col in df.columns:\n",
        "            df = df.drop(columns=col)\n",
        "\n",
        "    # Alternatively, without an explicit loop, using the dropna method\n",
        "    # df_cleaned = df.dropna(axis=1, thresh=len(df) * (1 - missing_threshold))\n",
        "    # Note: The loop method above achieves the same result as the dropna(thresh=...) approach\n",
        "\n",
        "    print(f\"New shape of the DataFrame (after dropping columns): {df.shape}\\n\")\n",
        "\n",
        "    # Print summary of missing value percentages for remaining columns\n",
        "    print(\"Missing value percentages for each remaining column:\")\n",
        "    remaining_missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
        "    print(remaining_missing_percentages.round(2).to_string())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the file name\n",
        "    file_name = '/content/student_enrollment_sample-Laurie_Bagley.csv'\n",
        "\n",
        "    # Run the function\n",
        "    process_enrollment_data(file_name, missing_threshold=0.30)\n"
      ],
      "metadata": {
        "id": "V41ZBw7Lqsfu",
        "outputId": "5d71fbbb-3540-452f-8af7-4a52e085d8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape of the DataFrame: (50001, 35)\n",
            "Number of columns to drop (>30.0% missing): 6\n",
            "Dropped columns: ['MINUTES_ATTENDED', 'MINUTES_ABSENT', 'MINUTES_MAKEUP', 'CUMMULATIVE_GPA', 'CUMMULATIVE_GPA_POINTS', 'CUMMULATIVE_GPA_CREDITS']\n",
            "\n",
            "New shape of the DataFrame (after dropping columns): (50001, 29)\n",
            "\n",
            "Missing value percentages for each remaining column:\n",
            "EXPECTED_START_DATE          3.74\n",
            "GRADUATION_DATE              3.20\n",
            "ENROLL_COUNT                 0.00\n",
            "NUMBER_AVERAGE               0.00\n",
            "HOURS_ATTEMPTED              0.00\n",
            "HOURS_EARNED                 0.00\n",
            "AR_BALANCE_AMOUNT            0.00\n",
            "DAYS_ABSENT                  0.00\n",
            "REENTRY_NUMBER               0.00\n",
            "PROGRAM_GROUP                0.03\n",
            "BIRTH_DATE                   2.72\n",
            "LAST_ACTIVITY_DATE           8.78\n",
            "MOD_NUMBER                   2.65\n",
            "COHORT_YEAR                  2.75\n",
            "AR_BALANCE                   2.65\n",
            "ENROLLMENT_GPA               2.64\n",
            "CREDITS_ATTEMPTED            2.65\n",
            "CREDITS_EARNED               2.65\n",
            "CREDITS_REQUIRED             2.67\n",
            "CREDITS_LEFT                 2.67\n",
            "ENROLLMENT_COUNT             2.65\n",
            "MODS_ATTENDED_COUNT          2.65\n",
            "HS_GRADUATED_FLAG            2.65\n",
            "DISABLED_FLAG                2.65\n",
            "HISPANIC_FLAG                2.65\n",
            "VETERAN_FLAG                 2.65\n",
            "STATUS_DESCRIPTION           0.00\n",
            "IN_SCHOOL_FLAG               0.00\n",
            "SIMPLE_STATUS_DESCRIPTION    0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4: Drop all remaining rows that contain any missing data.\n",
        "# Print out the numer of rows and columns in the remaining dataset.\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"\n",
        "    Loads a CSV file into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): The absolute path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The loaded DataFrame.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Error: The file '{filepath}' was not found.\")\n",
        "        print(\"Please ensure the path is correct and the file exists.\")\n",
        "        return None\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean_data(df):\n",
        "    \"\"\"\n",
        "    Cleans the DataFrame by removing columns with > 30% missing data\n",
        "    and dropping all remaining rows with any missing data.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The cleaned DataFrame.\n",
        "    \"\"\"\n",
        "    # 1. Remove columns with more than 30% missing data using a loop\n",
        "    initial_columns = df.shape[1]\n",
        "    cols_to_drop = []\n",
        "    for col in df.columns:\n",
        "        missing_percentage = (df[col].isnull().sum() / len(df)) * 100\n",
        "        if missing_percentage > 30:\n",
        "            cols_to_drop.append(col)\n",
        "\n",
        "    if cols_to_drop:\n",
        "        df = df.drop(columns=cols_to_drop)\n",
        "        print(f\"\\nDropped {len(cols_to_drop)} column(s) with >30% missing data: {', '.join(cols_to_drop)}\")\n",
        "    else:\n",
        "        print(\"\\nNo columns had more than 30% missing data.\")\n",
        "\n",
        "    # 2. Print a summary of missing value percentages for each remaining column\n",
        "    print(\"\\n--- Missing Value Percentages for Remaining Columns ---\")\n",
        "    missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
        "    print(missing_percentages.round(2).to_string() + '%')\n",
        "\n",
        "    # 3. Drop all remaining rows that contain any missing data\n",
        "    initial_rows = df.shape[0]\n",
        "    df_cleaned = df.dropna(axis=0)\n",
        "    rows_dropped = initial_rows - df_cleaned.shape[0]\n",
        "    print(f\"\\nDropped {rows_dropped} rows with any remaining missing data.\")\n",
        "\n",
        "    # 4. Print the number of rows and columns in the remaining dataset\n",
        "    print(\"\\n--- Final Dataset Summary ---\")\n",
        "    print(f\"Remaining rows: {df_cleaned.shape[0]}\")\n",
        "    print(f\"Remaining columns: {df_cleaned.shape[1]}\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# --- Main execution block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # !! IMPORTANT: Replace with the actual absolute path to your file !!\n",
        "    file_path = \"/content/student_enrollment_sample-Laurie_Bagley.csv\"\n",
        "\n",
        "    df = load_data(file_path)\n",
        "\n",
        "    if df is not None and not df.empty:\n",
        "        cleaned_df = clean_data(df)\n",
        "    elif df is not None and df.empty:\n",
        "        print(\"The loaded DataFrame is empty after initial loading.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "prmZq5VIqwlP",
        "outputId": "51f19a47-9c46-419c-9385-6dc88b499c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dropped 6 column(s) with >30% missing data: MINUTES_ATTENDED, MINUTES_ABSENT, MINUTES_MAKEUP, CUMMULATIVE_GPA, CUMMULATIVE_GPA_POINTS, CUMMULATIVE_GPA_CREDITS\n",
            "\n",
            "--- Missing Value Percentages for Remaining Columns ---\n",
            "EXPECTED_START_DATE          3.74\n",
            "GRADUATION_DATE              3.20\n",
            "ENROLL_COUNT                 0.00\n",
            "NUMBER_AVERAGE               0.00\n",
            "HOURS_ATTEMPTED              0.00\n",
            "HOURS_EARNED                 0.00\n",
            "AR_BALANCE_AMOUNT            0.00\n",
            "DAYS_ABSENT                  0.00\n",
            "REENTRY_NUMBER               0.00\n",
            "PROGRAM_GROUP                0.03\n",
            "BIRTH_DATE                   2.72\n",
            "LAST_ACTIVITY_DATE           8.78\n",
            "MOD_NUMBER                   2.65\n",
            "COHORT_YEAR                  2.75\n",
            "AR_BALANCE                   2.65\n",
            "ENROLLMENT_GPA               2.64\n",
            "CREDITS_ATTEMPTED            2.65\n",
            "CREDITS_EARNED               2.65\n",
            "CREDITS_REQUIRED             2.67\n",
            "CREDITS_LEFT                 2.67\n",
            "ENROLLMENT_COUNT             2.65\n",
            "MODS_ATTENDED_COUNT          2.65\n",
            "HS_GRADUATED_FLAG            2.65\n",
            "DISABLED_FLAG                2.65\n",
            "HISPANIC_FLAG                2.65\n",
            "VETERAN_FLAG                 2.65\n",
            "STATUS_DESCRIPTION           0.00\n",
            "IN_SCHOOL_FLAG               0.00\n",
            "SIMPLE_STATUS_DESCRIPTION    0.00%\n",
            "\n",
            "Dropped 5036 rows with any remaining missing data.\n",
            "\n",
            "--- Final Dataset Summary ---\n",
            "Remaining rows: 44965\n",
            "Remaining columns: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Now it's time to handle the date values. LAST_ACTIVITY_DATE,\n",
        "# EXPECTED_START_DATE, BIRTH_DATE, and GRADUATION_DATE may all be useful.\n",
        "# For LAST_ACTIVITY_DATE, EXPECTED_START_DATE, and BIRTH_DATE, replace the\n",
        "# date value with the number of days between that date and 2022-1-1. In other\n",
        "# words: 2022-1-1 minus the date value in the field. For GRADUATION_DATE,\n",
        "# replace the date value with the number of days until graduation assuming\n",
        "# that today's date is 2020-1-1. In other words, calculate: GRADUATION_DATE\n",
        "# minus 2020-1-1. Print out the first five rows to examine the results.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def process_student_data(file_path):\n",
        "    # 1. Import the data file\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: The file 'student_enrollment_sample.csv' was not found. Please ensure it is in the same directory as the script or provide the correct full path.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during file reading: {e}\"\n",
        "\n",
        "    # Ensure date columns are converted to datetime objects\n",
        "    date_cols = ['LAST_ACTIVITY_DATE', 'EXPECTED_START_DATE', 'BIRTH_DATE', 'GRADUATION_DATE']\n",
        "    for col in date_cols:\n",
        "        if col in df.columns:\n",
        "            # errors='coerce' will turn unparseable dates into NaT (Not a Time)\n",
        "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "    # Define reference dates\n",
        "    ref_date_2022 = pd.to_datetime('2022-01-01')\n",
        "    ref_date_2020 = pd.to_datetime('2020-01-01')\n",
        "\n",
        "    # 2. Handle LAST_ACTIVITY_DATE, EXPECTED_START_DATE, BIRTH_DATE\n",
        "    # Calculate: 2022-1-1 minus the date value\n",
        "    for col in ['LAST_ACTIVITY_DATE', 'EXPECTED_START_DATE', 'BIRTH_DATE']:\n",
        "        if col in df.columns:\n",
        "            # The result is a Timedelta; .dt.days extracts the integer number of days\n",
        "            df[col] = (ref_date_2022 - df[col]).dt.days\n",
        "\n",
        "    # 3. Handle GRADUATION_DATE\n",
        "    # Calculate: GRADUATION_DATE minus 2020-1-1 (assuming today's date is 2020-1-1)\n",
        "    if 'GRADUATION_DATE' in df.columns:\n",
        "        df['GRADUATION_DATE'] = (df['GRADUATION_DATE'] - ref_date_2020).dt.days\n",
        "\n",
        "    # Print the first five rows to examine the results\n",
        "    print(\"First five rows of the processed DataFrame:\")\n",
        "    print(df.head())\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # 4. How many days until record 1873 graduates?\n",
        "    # DataFrames are 0-indexed, so record 1873 is at index 1872\n",
        "    record_index = 1872\n",
        "    if record_index < len(df):\n",
        "        days_to_grad = df.loc[record_index, 'GRADUATION_DATE']\n",
        "        # Check if the value is a number (not NaN from a bad date conversion)\n",
        "        if pd.notna(days_to_grad):\n",
        "            print(f\"Record 1873 (index {record_index}) has {int(days_to_grad)} days until graduation (relative to 2020-01-01).\")\n",
        "        else:\n",
        "            print(f\"Graduation date for record 1873 (index {record_index}) is missing or invalid.\")\n",
        "    else:\n",
        "        print(f\"Record 1873 (index {record_index}) does not exist in the DataFrame.\")\n",
        "\n",
        "    return \"\" # Return empty string as all output is in prints\n",
        "\n",
        "# Run the processing function\n",
        "# Note: The file 'student_enrollment_sample.csv' must be present in the execution directory.\n",
        "# If not, provide the full path, e.g., 'C:/Users/YourUser/Desktop/student_enrollment_sample.csv'\n",
        "result_message = process_student_data('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "if result_message:\n",
        "    print(result_message)\n"
      ],
      "metadata": {
        "id": "7PzOUvXQq0jd",
        "outputId": "24a8d13b-d34f-4b85-8ce4-9cbebc23a726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five rows of the processed DataFrame:\n",
            "   EXPECTED_START_DATE  GRADUATION_DATE  ENROLL_COUNT  NUMBER_AVERAGE  \\\n",
            "0                  NaN              NaN           1.0             0.0   \n",
            "1                  NaN          -1423.0           1.0             0.0   \n",
            "2                  NaN              NaN           1.0             0.0   \n",
            "3                  NaN              NaN           1.0             0.0   \n",
            "4                  NaN              NaN           1.0             0.0   \n",
            "\n",
            "   MINUTES_ATTENDED  HOURS_ATTEMPTED  HOURS_EARNED  AR_BALANCE_AMOUNT  \\\n",
            "0               NaN              0.0           0.0                0.0   \n",
            "1               NaN              0.0           0.0                0.0   \n",
            "2               NaN              0.0           0.0                0.0   \n",
            "3               NaN              0.0           0.0                0.0   \n",
            "4               NaN              0.0           0.0                0.0   \n",
            "\n",
            "   MINUTES_ABSENT  DAYS_ABSENT  ...  CREDITS_LEFT  ENROLLMENT_COUNT  \\\n",
            "0             NaN          0.0  ...           NaN               NaN   \n",
            "1             NaN          0.0  ...           NaN               NaN   \n",
            "2             NaN          0.0  ...         180.0               2.0   \n",
            "3             NaN          0.0  ...          60.0               3.0   \n",
            "4             NaN          0.0  ...           NaN               NaN   \n",
            "\n",
            "  MODS_ATTENDED_COUNT  HS_GRADUATED_FLAG  DISABLED_FLAG  HISPANIC_FLAG  \\\n",
            "0                 NaN                NaN            NaN            NaN   \n",
            "1                 NaN                NaN            NaN            NaN   \n",
            "2                 0.0                0.0            0.0            0.0   \n",
            "3                 0.0                0.0            0.0            1.0   \n",
            "4                 NaN                NaN            NaN            NaN   \n",
            "\n",
            "   VETERAN_FLAG               STATUS_DESCRIPTION  IN_SCHOOL_FLAG  \\\n",
            "0           NaN            Application Cancelled             0.0   \n",
            "1           NaN                        Applicant             0.0   \n",
            "2           0.0  Pending Applicant - Portal Only             0.0   \n",
            "3           0.0                        Applicant             0.0   \n",
            "4           NaN  Pending Applicant - Portal Only             0.0   \n",
            "\n",
            "   SIMPLE_STATUS_DESCRIPTION  \n",
            "0                      Other  \n",
            "1                      Other  \n",
            "2                      Other  \n",
            "3                      Other  \n",
            "4                      Other  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "------------------------------\n",
            "Record 1873 (index 1872) has 1040 days until graduation (relative to 2020-01-01).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: The PROGRAM_GROUP feature indicates which academic program\n",
        "# the student is working on. Some of them are very small programs and\n",
        "# represent less than five percent of the data. We need to bin those programs\n",
        "# into a new value called \"Other\". Start by printing a list of PROGRAM_GROUP\n",
        "# values divided by the total number of records in order to see what percent\n",
        "# of the cases they represent. Then, iterate through the rows and change every\n",
        "# program value to \"Other\" if it does not belong to a PROGRAM_GROUP that\n",
        "# represents at least five percent of the cases. Finally, print out the new\n",
        "# listof PROGRAM_GROUP values (including the new 'Other') to make sure your\n",
        "# routine worked correctly. You do not need to print the values in 'percent'\n",
        "# format. The original decimal values are fine.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    df = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: '/content/student_enrollment_sample-Laurie_Bagley.csv' not found. Please ensure the file is in the same directory as the script.\")\n",
        "    exit()\n",
        "\n",
        "# Calculate and print initial PROGRAM_GROUP proportions\n",
        "total_records = len(df)\n",
        "initial_proportions = df['PROGRAM_GROUP'].value_counts() / total_records\n",
        "print(\"Initial PROGRAM_GROUP proportions:\")\n",
        "print(initial_proportions)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Identify PROGRAM_GROUPs representing less than 5%\n",
        "threshold = 0.05\n",
        "to_bin_to_other = initial_proportions[initial_proportions < threshold].index\n",
        "\n",
        "# Bin programs into 'Other'\n",
        "df['PROGRAM_GROUP_BINNED'] = df['PROGRAM_GROUP'].apply(lambda x: 'Other' if x in to_bin_to_other else x)\n",
        "\n",
        "# Calculate and print new PROGRAM_GROUP proportions\n",
        "new_proportions = df['PROGRAM_GROUP_BINNED'].value_counts() / total_records\n",
        "print(\"New PROGRAM_GROUP proportions (with 'Other'):\")\n",
        "print(new_proportions)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Find the program with the most students enrolled\n",
        "most_enrolled_program = df['PROGRAM_GROUP_BINNED'].value_counts().idxmax()\n",
        "print(f\"The program with the most students enrolled is: {most_enrolled_program}\")\n",
        "\n",
        "# Determine the five-letter acronym for the program with the most students (assuming it's not 'Other')\n",
        "# If 'Other' is the most enrolled, we would need to look at the original data before binning for the most frequent *original* program\n",
        "# For this specific request, we are looking at the *binned* data.\n",
        "# Assuming the question implies the most enrolled *original* program if 'Other' is the highest after binning,\n",
        "# we would need to re-evaluate the original `PROGRAM_GROUP`.\n",
        "# However, the prompt asks for the five-letter acronym of *the* program with the most students enrolled from the *final* list.\n",
        "# If 'Other' is the most enrolled, there's no single five-letter acronym.\n",
        "# Let's assume the question refers to the most frequent *original* program that wasn't binned, or the most frequent *binned* program if it's not 'Other'.\n",
        "\n",
        "# To answer the specific question about the five-letter acronym, we need to consider the program with the most students *before* binning,\n",
        "# unless 'Other' is the most frequent after binning.\n",
        "# Re-evaluating the most enrolled *original* program for the acronym.\n",
        "original_most_enrolled_program_acronym = df['PROGRAM_GROUP'].value_counts().idxmax()\n",
        "print(f\"The five-letter acronym for the program with the most students (original) is: {original_most_enrolled_program_acronym}\")\n"
      ],
      "metadata": {
        "id": "oHP_lvGwq-Rb",
        "outputId": "2915bba1-aa79-4205-de17-8b68e8b55fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial PROGRAM_GROUP proportions:\n",
            "PROGRAM_GROUP\n",
            "GAGAB      0.271295\n",
            "MSMAA      0.229935\n",
            "HSHMB      0.133697\n",
            "CSSMB      0.098898\n",
            "CSCNB      0.095838\n",
            "BUBAB      0.094518\n",
            "unknown    0.026439\n",
            "GAWDB      0.019580\n",
            "ACACB      0.009760\n",
            "BUBMA      0.003260\n",
            "CSCSB      0.003100\n",
            "MSMSA      0.002320\n",
            "RTRCB      0.001820\n",
            "BUBUA      0.001480\n",
            "GAGAA      0.001320\n",
            "CSISM      0.001200\n",
            "NUNUB      0.000860\n",
            "RTRTA      0.000820\n",
            "NDAUI      0.000760\n",
            "BUBUD      0.000480\n",
            "HSSTA      0.000480\n",
            "BUBAM      0.000460\n",
            "CSCNA      0.000360\n",
            "HSHIB      0.000240\n",
            "HSHSB      0.000180\n",
            "NUNEA      0.000140\n",
            "HSPHM      0.000120\n",
            "NUNAM      0.000100\n",
            "CSNIB      0.000060\n",
            "HSHAB      0.000040\n",
            "HSHAM      0.000040\n",
            "NUNUA      0.000020\n",
            "CSCS       0.000020\n",
            "NUNAB      0.000020\n",
            "GAWDD      0.000020\n",
            "HSHIM      0.000020\n",
            "NUNEM      0.000020\n",
            "Name: count, dtype: float64\n",
            "\n",
            "\n",
            "New PROGRAM_GROUP proportions (with 'Other'):\n",
            "PROGRAM_GROUP_BINNED\n",
            "GAGAB    0.271295\n",
            "MSMAA    0.229935\n",
            "HSHMB    0.133697\n",
            "CSSMB    0.098898\n",
            "CSCNB    0.095838\n",
            "BUBAB    0.094518\n",
            "Other    0.075538\n",
            "Name: count, dtype: float64\n",
            "\n",
            "\n",
            "The program with the most students enrolled is: GAGAB\n",
            "The five-letter acronym for the program with the most students (original) is: GAGAB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Print the first five records of a filtered version of\n",
        "# the DataFrame including only the 'IN_SCHOOL_FLAG' and 'STATUS_DESCRIPTION'\n",
        "# features. Notice that all those who have graduated have an 'IN_SCHOOL_FLAG'\n",
        "# of zero which makes them the same as students who have dropped out or\n",
        "# have been terminated. Because we want students to graduate, we need to\n",
        "# treat them the same as those who are active. Therefore, convert the\n",
        "# 'IN_SCHOOL_FLAG' value for all graduates to 1 (or 1.0). In addition, convert\n",
        "# their 'SIMPLE_STATUS_DESCRIPTION' to 'Active'.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the file name\n",
        "file_name = '/content/student_enrollment_sample-Laurie_Bagley.csv'\n",
        "\n",
        "# Import the data file into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(file_name)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_name}' was not found.\")\n",
        "    print(\"Please make sure the CSV file is in the same directory as this script.\")\n",
        "    exit()\n",
        "\n",
        "# Create the filtered DataFrame with only the specified columns\n",
        "filtered_df = df[['IN_SCHOOL_FLAG', 'STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION']].copy()\n",
        "\n",
        "# Print the first five records of the original filtered data to observe initial state (optional)\n",
        "# print(\"First five records before changes:\")\n",
        "# print(filtered_df.head())\n",
        "\n",
        "# --- Data Transformation ---\n",
        "\n",
        "# 1. Identify records where the student has 'GRADUATED'\n",
        "is_graduated = filtered_df['STATUS_DESCRIPTION'] == 'GRADUATED'\n",
        "\n",
        "# 2. Convert the 'IN_SCHOOL_FLAG' value for all graduates to 1.0\n",
        "# We use .loc to modify the original DataFrame safely\n",
        "filtered_df.loc[is_graduated, 'IN_SCHOOL_FLAG'] = 1.0\n",
        "\n",
        "# 3. Convert the 'SIMPLE_STATUS_DESCRIPTION' for graduates to 'Active'\n",
        "filtered_df.loc[is_graduated, 'SIMPLE_STATUS_DESCRIPTION'] = 'Active'\n",
        "\n",
        "# --- Output ---\n",
        "\n",
        "print(\"\\nFirst five records after changes (if any graduates are present in the head):\")\n",
        "# Print the first five records of the updated DataFrame\n",
        "print(filtered_df.head())\n",
        "\n",
        "# Optional: Print all records where STATUS_DESCRIPTION is 'GRADUATED' to verify the changes were applied\n",
        "# print(\"\\nVerification of changes for all graduated students:\")\n",
        "# print(filtered_df[filtered_df['STATUS_DESCRIPTION'] == 'GRADUATED'])\n"
      ],
      "metadata": {
        "id": "bkR0heTrrDUe",
        "outputId": "53bcbe5c-2fa9-42d2-a7b2-d2d4bec762c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First five records after changes (if any graduates are present in the head):\n",
            "   IN_SCHOOL_FLAG               STATUS_DESCRIPTION SIMPLE_STATUS_DESCRIPTION\n",
            "0             0.0            Application Cancelled                     Other\n",
            "1             0.0                        Applicant                     Other\n",
            "2             0.0  Pending Applicant - Portal Only                     Other\n",
            "3             0.0                        Applicant                     Other\n",
            "4             0.0  Pending Applicant - Portal Only                     Other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Import the packages necessary for a DecisionTreeClassifier and\n",
        "# a train_test_split. We will use these later. For now, create another copy of the\n",
        "# latest DataFrame to work from. Using the new copy, convert MOD_NUMBER and\n",
        "# COHORT_YEAR to 'object' data types. That is because those values are numbers\n",
        "# but, theoretically, they represent categorical values. Drop STATUS_DESCRIPTION\n",
        "# and SIMPLE_STATUS_DESCRIPTION from the new DataFrame since those are alternative\n",
        "# labels and we are going to use IN_SCHOOL_FLAG as the two-class label for our first\n",
        "# model. Create dummy codes for all remaining features in the new DataFrame. Print\n",
        "# out the first five records of the new DataFrame. There should be no remaining\n",
        "# categorical values and many new dummy code features.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the file path (assuming the CSV is in the same directory)\n",
        "file_path = '/content/student_enrollment_sample-Laurie_Bagley.csv'\n",
        "\n",
        "# Import the data file into the original DataFrame\n",
        "try:\n",
        "    df_original = pd.read_csv(file_path)\n",
        "    print(f\"Successfully imported data from {file_path}\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    print(\"Please make sure the CSV file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# Create another copy of the original DataFrame to work from\n",
        "df_processed = df_original.copy()\n",
        "\n",
        "# Convert specified columns to 'object' (categorical) data types\n",
        "df_processed['MOD_NUMBER'] = df_processed['MOD_NUMBER'].astype('object')\n",
        "df_processed['COHORT_YEAR'] = df_processed['COHORT_YEAR'].astype('object')\n",
        "print(\"Converted MOD_NUMBER and COHORT_YEAR to 'object' data types.\\n\")\n",
        "\n",
        "# Drop the specified label columns\n",
        "df_processed = df_processed.drop(columns=['STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION'])\n",
        "print(\"Dropped STATUS_DESCRIPTION and SIMPLE_STATUS_DESCRIPTION.\\n\")\n",
        "\n",
        "# Create dummy codes for all remaining features in the DataFrame\n",
        "# get_dummies automatically handles all 'object' type columns (which now includes the converted columns)\n",
        "df_processed = pd.get_dummies(df_processed, drop_first=True)\n",
        "print(\"Created dummy codes for all remaining features using pd.get_dummies.\\n\")\n",
        "\n",
        "# Print out the first five records of the new DataFrame\n",
        "print(\"First five records of the processed DataFrame (no remaining categorical values):\\n\")\n",
        "print(df_processed.head())\n",
        "\n",
        "# Print information to confirm data types\n",
        "print(\"\\nDataFrame Info after processing:\")\n",
        "df_processed.info()\n"
      ],
      "metadata": {
        "id": "HOYOOUw_rGgI",
        "outputId": "c47cc1cc-9c72-4c9d-e318-d7a8bbb44036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported data from /content/student_enrollment_sample-Laurie_Bagley.csv\n",
            "\n",
            "Converted MOD_NUMBER and COHORT_YEAR to 'object' data types.\n",
            "\n",
            "Dropped STATUS_DESCRIPTION and SIMPLE_STATUS_DESCRIPTION.\n",
            "\n",
            "Created dummy codes for all remaining features using pd.get_dummies.\n",
            "\n",
            "First five records of the processed DataFrame (no remaining categorical values):\n",
            "\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13626 columns]\n",
            "\n",
            "DataFrame Info after processing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50001 entries, 0 to 50000\n",
            "Columns: 13626 entries, ENROLL_COUNT to COHORT_YEAR_2026.0\n",
            "dtypes: bool(13600), float64(26)\n",
            "memory usage: 658.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Set the y and X variables to represent the label\n",
        "# and feature set. Print out the first five records of the feature\n",
        "# list to verify it looks correct.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Import the data file 'student_enrollment_sample.csv'\n",
        "# Assuming the file is in the same directory as the script.\n",
        "# Replace 'student_enrollment_sample.csv' with the correct path if it is different.\n",
        "original_df = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "\n",
        "# Create another copy of the latest DataFrame to work from\n",
        "new_df = original_df.copy()\n",
        "\n",
        "# Convert MOD_NUMBER and COHORT_YEAR to 'object' (categorical) data types\n",
        "new_df['MOD_NUMBER'] = new_df['MOD_NUMBER'].astype('object')\n",
        "new_df['COHORT_YEAR'] = new_df['COHORT_YEAR'].astype('object')\n",
        "\n",
        "# Drop STATUS_DESCRIPTION and SIMPLE_STATUS_DESCRIPTION\n",
        "new_df = new_df.drop(['STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION'], axis=1)\n",
        "\n",
        "# Create dummy codes for all remaining features in the new DataFrame\n",
        "# This performs one-hot encoding on all 'object' dtype columns automatically\n",
        "new_df = pd.get_dummies(new_df, drop_first=True)\n",
        "\n",
        "# Print out the first five records of the new DataFrame to verify no remaining categorical values\n",
        "print(\"First five records of the DataFrame after dummy coding:\")\n",
        "print(new_df.head())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Set the y and x variables to represent the label (IN_SCHOOL_FLAG) and feature set\n",
        "y = new_df['IN_SCHOOL_FLAG']\n",
        "# X includes all columns except the label\n",
        "X = new_df.drop('IN_SCHOOL_FLAG', axis=1)\n",
        "\n",
        "# Print out the first five records of the feature list (X) to verify it looks correct\n",
        "print(\"First five records of the feature list (X):\")\n",
        "print(X.head())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# The DecisionTreeClassifier and train_test_split packages are imported\n",
        "# and available for use in subsequent steps.\n"
      ],
      "metadata": {
        "id": "b8wsqYcDrLbA",
        "outputId": "7ec45048-45f9-4471-b75a-1c9af11f530d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five records of the DataFrame after dummy coding:\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13626 columns]\n",
            "------------------------------\n",
            "First five records of the feature list (X):\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13625 columns]\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 10: Split the y and X sets into training and testing sets. Do\n",
        "# a 70/30 split meaning 70% training data. Use a random seed of 12345.\n",
        "# Print out the first five records of the X_test dataset.\n",
        "\n",
        "#import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the file path (assuming the file is in the same directory as the script)\n",
        "file_path = '/content/student_enrollment_sample-Laurie_Bagley.csv'\n",
        "\n",
        "# Import the data file into a DataFrame\n",
        "original_df = pd.read_csv(file_path)\n",
        "\n",
        "# Create another copy of the DataFrame to work from\n",
        "new_df = original_df.copy()\n",
        "\n",
        "# Convert specified columns to 'object' (categorical) data types\n",
        "new_df['MOD_NUMBER'] = new_df['MOD_NUMBER'].astype('object')\n",
        "new_df['COHORT_YEAR'] = new_df['COHORT_YEAR'].astype('object')\n",
        "\n",
        "# Drop specified columns\n",
        "new_df = new_df.drop(['STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION'], axis=1)\n",
        "\n",
        "# Create dummy codes for all remaining features\n",
        "# get_dummies automatically handles only object/categorical columns if specified,\n",
        "# but passing the whole DF works as well, turning all categorical columns into dummies.\n",
        "new_df_encoded = pd.get_dummies(new_df, drop_first=True) # drop_first=True avoids multicollinearity\n",
        "\n",
        "# Print out the first five records of the new DataFrame to verify no remaining categorical values\n",
        "print(\"First five records of the encoded DataFrame:\")\n",
        "print(new_df_encoded.head())\n",
        "print(\"\\nDataFrame info to confirm data types:\")\n",
        "print(new_df_encoded.info())\n",
        "\n",
        "# Define the label (y) and features (x)\n",
        "y = new_df_encoded['IN_SCHOOL_FLAG']\n",
        "# Drop the label from the features set\n",
        "x = new_df_encoded.drop('IN_SCHOOL_FLAG', axis=1)\n",
        "\n",
        "# Split the y and x sets into training and testing sets (70/30 split, random seed 12345)\n",
        "# train_size=0.7 specifies the 70% training data size\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x, y, train_size=0.7, random_state=12345\n",
        ")\n",
        "\n",
        "# Print out the first five records of the X_test dataset\n",
        "print(\"\\nFirst five records of the X_test dataset:\")\n",
        "print(X_test.head())"
      ],
      "metadata": {
        "id": "rkdwroTXrOeu",
        "outputId": "15beab2c-cf7e-4f28-b7c3-4baddae6de54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five records of the encoded DataFrame:\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13626 columns]\n",
            "\n",
            "DataFrame info to confirm data types:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50001 entries, 0 to 50000\n",
            "Columns: 13626 entries, ENROLL_COUNT to COHORT_YEAR_2026.0\n",
            "dtypes: bool(13600), float64(26)\n",
            "memory usage: 658.4 MB\n",
            "None\n",
            "\n",
            "First five records of the X_test dataset:\n",
            "       ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "43398           1.0        0.000000               0.0              0.0   \n",
            "549             1.0        0.000000               NaN              0.0   \n",
            "32087           1.0       83.883041            8400.0            859.0   \n",
            "27425           1.0        0.000000               NaN              0.0   \n",
            "25364           1.0        0.000000               0.0              0.0   \n",
            "\n",
            "       HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "43398           0.0                0.0             0.0          0.0   \n",
            "549             0.0                0.0             NaN          0.0   \n",
            "32087         805.0             -445.0             0.0          0.0   \n",
            "27425           0.0                0.0             NaN          0.0   \n",
            "25364           0.0                0.0             0.0          0.0   \n",
            "\n",
            "       MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "43398             0.0             0.0  ...               False   \n",
            "549               NaN             0.0  ...                True   \n",
            "32087             0.0             0.0  ...               False   \n",
            "27425             NaN             0.0  ...               False   \n",
            "25364             0.0             0.0  ...               False   \n",
            "\n",
            "       COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "43398               False               False               False   \n",
            "549                 False               False               False   \n",
            "32087               False               False               False   \n",
            "27425               False               False               False   \n",
            "25364               False               False               False   \n",
            "\n",
            "       COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "43398               False               False               False   \n",
            "549                 False               False               False   \n",
            "32087               False               False               False   \n",
            "27425               False               False                True   \n",
            "25364               False               False               False   \n",
            "\n",
            "       COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "43398               False                True               False  \n",
            "549                 False               False               False  \n",
            "32087               False               False                True  \n",
            "27425               False               False               False  \n",
            "25364               False               False                True  \n",
            "\n",
            "[5 rows x 13625 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 11: Create and fit a DecisionTreeClassifier() model using the\n",
        "# training datasets.\n",
        "\n",
        "#import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the file path provided in the assignment description\n",
        "file_path = '/content/student_enrollment_sample-Laurie_Bagley.csv'\n",
        "\n",
        "# --- Import and initial setup ---\n",
        "\n",
        "# Import the data file into a DataFrame\n",
        "try:\n",
        "    original_df = pd.read_csv(file_path)\n",
        "    print(f\"Successfully loaded data from {file_path}\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {file_path} was not found. Please ensure the file is correctly uploaded to the specified path.\")\n",
        "    exit()\n",
        "\n",
        "# Create another copy of the DataFrame to work from\n",
        "df = original_df.copy()\n",
        "\n",
        "# --- Data Preparation and Conversion ---\n",
        "\n",
        "# Convert specified columns to 'object' data types (categorical representation)\n",
        "print(\"Converting MOD_NUMBER and COHORT_YEAR to object (categorical) data type...\")\n",
        "df['MOD_NUMBER'] = df['MOD_NUMBER'].astype('object')\n",
        "df['COHORT_YEAR'] = df['COHORT_YEAR'].astype('object')\n",
        "\n",
        "# Drop specified columns (alternative labels)\n",
        "print(\"Dropping STATUS_DESCRIPTION and SIMPLE_STATUS_DESCRIPTION...\")\n",
        "df = df.drop(['STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION'], axis=1)\n",
        "\n",
        "# Create dummy codes (one-hot encoding) for all remaining categorical features\n",
        "print(\"Creating dummy codes for all remaining categorical features...\\n\")\n",
        "df = pd.get_dummies(df, drop_first=True) # drop_first=True avoids the dummy variable trap\n",
        "\n",
        "# Print out the first five records of the new DataFrame to verify no categorical values remain\n",
        "print(\"First five records of the final DataFrame (after dummy coding):\")\n",
        "print(df.head())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Define Features (X) and Label (y) ---\n",
        "\n",
        "# Set y variable to represent the label (target)\n",
        "y = df['IN_SCHOOL_FLAG']\n",
        "\n",
        "# Set x variables to represent the feature set (drop the target column from X)\n",
        "X = df.drop('IN_SCHOOL_FLAG', axis=1)\n",
        "\n",
        "# Print out the first five records of the feature list to verify it looks correct\n",
        "print(\"First five records of the feature list (X):\")\n",
        "print(X.head())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "\n",
        "# Split the y and x sets into training and testing sets (70/30 split, random seed 12345)\n",
        "print(\"Splitting data into 70/30 train/test sets with random seed 12345...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
        "\n",
        "# Print out the first five records of the X_test dataset\n",
        "print(\"First five records of the X_test dataset:\")\n",
        "print(X_test.head())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Model Creation and Fitting ---\n",
        "\n",
        "# Create a DecisionTreeClassifier() model\n",
        "print(\"Creating a DecisionTreeClassifier model...\")\n",
        "model = DecisionTreeClassifier(random_state=12345) # Setting random_state for reproducibility\n",
        "\n",
        "# Fit the model using the training datasets\n",
        "print(\"Fitting the model using training data (X_train, y_train)...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nModel fitting complete.\")\n"
      ],
      "metadata": {
        "id": "xSDDtiaQrXxr",
        "outputId": "2ef6aba4-6de2-4861-e5ea-112737edfa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from /content/student_enrollment_sample-Laurie_Bagley.csv\n",
            "\n",
            "Converting MOD_NUMBER and COHORT_YEAR to object (categorical) data type...\n",
            "Dropping STATUS_DESCRIPTION and SIMPLE_STATUS_DESCRIPTION...\n",
            "Creating dummy codes for all remaining categorical features...\n",
            "\n",
            "First five records of the final DataFrame (after dummy coding):\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13626 columns]\n",
            "--------------------------------------------------\n",
            "First five records of the feature list (X):\n",
            "   ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "0           1.0             0.0               NaN              0.0   \n",
            "1           1.0             0.0               NaN              0.0   \n",
            "2           1.0             0.0               NaN              0.0   \n",
            "3           1.0             0.0               NaN              0.0   \n",
            "4           1.0             0.0               NaN              0.0   \n",
            "\n",
            "   HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "0           0.0                0.0             NaN          0.0   \n",
            "1           0.0                0.0             NaN          0.0   \n",
            "2           0.0                0.0             NaN          0.0   \n",
            "3           0.0                0.0             NaN          0.0   \n",
            "4           0.0                0.0             NaN          0.0   \n",
            "\n",
            "   MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "0             NaN             0.0  ...               False   \n",
            "1             NaN             0.0  ...               False   \n",
            "2             NaN             0.0  ...               False   \n",
            "3             NaN             0.0  ...                True   \n",
            "4             NaN             0.0  ...               False   \n",
            "\n",
            "   COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False                True   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "0               False               False               False   \n",
            "1               False               False               False   \n",
            "2               False               False               False   \n",
            "3               False               False               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "0               False               False               False  \n",
            "1               False               False               False  \n",
            "2               False               False               False  \n",
            "3               False               False               False  \n",
            "4               False               False               False  \n",
            "\n",
            "[5 rows x 13625 columns]\n",
            "--------------------------------------------------\n",
            "Splitting data into 70/30 train/test sets with random seed 12345...\n",
            "First five records of the X_test dataset:\n",
            "       ENROLL_COUNT  NUMBER_AVERAGE  MINUTES_ATTENDED  HOURS_ATTEMPTED  \\\n",
            "43398           1.0        0.000000               0.0              0.0   \n",
            "549             1.0        0.000000               NaN              0.0   \n",
            "32087           1.0       83.883041            8400.0            859.0   \n",
            "27425           1.0        0.000000               NaN              0.0   \n",
            "25364           1.0        0.000000               0.0              0.0   \n",
            "\n",
            "       HOURS_EARNED  AR_BALANCE_AMOUNT  MINUTES_ABSENT  DAYS_ABSENT  \\\n",
            "43398           0.0                0.0             0.0          0.0   \n",
            "549             0.0                0.0             NaN          0.0   \n",
            "32087         805.0             -445.0             0.0          0.0   \n",
            "27425           0.0                0.0             NaN          0.0   \n",
            "25364           0.0                0.0             0.0          0.0   \n",
            "\n",
            "       MINUTES_MAKEUP  REENTRY_NUMBER  ...  COHORT_YEAR_2017.0  \\\n",
            "43398             0.0             0.0  ...               False   \n",
            "549               NaN             0.0  ...                True   \n",
            "32087             0.0             0.0  ...               False   \n",
            "27425             NaN             0.0  ...               False   \n",
            "25364             0.0             0.0  ...               False   \n",
            "\n",
            "       COHORT_YEAR_2018.0  COHORT_YEAR_2019.0  COHORT_YEAR_2020.0  \\\n",
            "43398               False               False               False   \n",
            "549                 False               False               False   \n",
            "32087               False               False               False   \n",
            "27425               False               False               False   \n",
            "25364               False               False               False   \n",
            "\n",
            "       COHORT_YEAR_2021.0  COHORT_YEAR_2022.0  COHORT_YEAR_2023.0  \\\n",
            "43398               False               False               False   \n",
            "549                 False               False               False   \n",
            "32087               False               False               False   \n",
            "27425               False               False                True   \n",
            "25364               False               False               False   \n",
            "\n",
            "       COHORT_YEAR_2024.0  COHORT_YEAR_2025.0  COHORT_YEAR_2026.0  \n",
            "43398               False                True               False  \n",
            "549                 False               False               False  \n",
            "32087               False               False                True  \n",
            "27425               False               False               False  \n",
            "25364               False               False                True  \n",
            "\n",
            "[5 rows x 13625 columns]\n",
            "--------------------------------------------------\n",
            "Creating a DecisionTreeClassifier model...\n",
            "Fitting the model using training data (X_train, y_train)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3700907839.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Fit the model using the training datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting the model using training data (X_train, y_train)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModel fitting complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n\u001b[1;32m    251\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             X, y = validate_data(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2957\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 12: Generate predictions for the testing dataset. Add the\n",
        "# predicted values to a new DataFrame along with the actual values and\n",
        "# print out the first 10 records. How many of the records are inaccurate?\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'student_enrollment_sample-Laurie_Bagley.csv' was not found.\")\n",
        "    print(\"Please ensure the file is correctly uploaded to '/content/'.\")\n",
        "    exit()\n",
        "\n",
        "# Assuming 'Actual_Enrollment' is the target variable and other numerical columns are features\n",
        "# You might need to adjust features based on your dataset\n",
        "features = df.select_dtypes(include=['number']).drop(columns=['Actual_Enrollment'], errors='ignore').columns\n",
        "target = 'Actual_Enrollment'\n",
        "\n",
        "# Handle potential missing values (simple imputation for demonstration)\n",
        "df[features] = df[features].fillna(df[features].mean())\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions on the testing dataset\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Create a new DataFrame with actual and predicted values\n",
        "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
        "\n",
        "# Print the first 10 records of the results DataFrame\n",
        "print(results_df.head(10))"
      ],
      "metadata": {
        "id": "dhH8IxehrbOp",
        "outputId": "ea0a2d19-14b3-44b1-e715-f193c4bb2126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Actual_Enrollment'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Actual_Enrollment'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3456436938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Actual_Enrollment'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 13: Generate a confusion matrix for the results. How many\n",
        "# students are active, but predicted to quit?\n"
      ],
      "metadata": {
        "id": "6YoHwsDjrf3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 14: Generate the accuracy, precision, recall, and f1 scores for\n",
        "# the predictions of active students. What is the accuracy score?\n"
      ],
      "metadata": {
        "id": "jj66cTfQrjmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 15: Generate a tree visualization using export_graphviz.\n",
        "# What feature is used in the most important feature?\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# --- 1. Load the data ---\n",
        "# Assuming the file is available at the specified path in the environment\n",
        "df = pd.read_csv('/content/student_enrollment_sample-Laurie_Bagley.csv')\n",
        "\n",
        "# Create a copy to work from as requested\n",
        "df_processed = df.copy()\n",
        "\n",
        "# --- 2. Convert data types ---\n",
        "df_processed['MOD_NUMBER'] = df_processed['MOD_NUMBER'].astype('object')\n",
        "df_processed['COHORT_YEAR'] = df_processed['COHORT_YEAR'].astype('object')\n",
        "\n",
        "# --- 3. Drop unnecessary columns ---\n",
        "# Keep IN_SCHOOL_FLAG as the target variable\n",
        "columns_to_drop = ['STATUS_DESCRIPTION', 'SIMPLE_STATUS_DESCRIPTION']\n",
        "df_processed = df_processed.drop(columns=columns_to_drop)\n",
        "\n",
        "# --- 4. Create dummy codes for all remaining features ---\n",
        "# The target variable 'IN_SCHOOL_FLAG' is already numeric (0 or 1), so it's not dummied.\n",
        "df_processed = pd.get_dummies(df_processed, drop_first=True, dtype=int)\n",
        "\n",
        "# Print the first five records of the processed DataFrame\n",
        "print(\"--- First five records of the processed DataFrame (after dummification) ---\")\n",
        "print(df_processed.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 5. Define y and x variables ---\n",
        "y = df_processed['IN_SCHOOL_FLAG']\n",
        "X = df_processed.drop(columns=['IN_SCHOOL_FLAG']) # All other columns are features\n",
        "\n",
        "# Print the first five records of the feature list (X)\n",
        "print(\"--- First five records of the feature set (X) ---\")\n",
        "print(X.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 6. Split data into training and testing sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3, # 30% testing, 70% training\n",
        "    random_state=12345,\n",
        "    stratify=y # Stratify to maintain class distribution in splits\n",
        ")\n",
        "\n",
        "# Print the first five records of the X_test dataset\n",
        "print(\"--- First five records of the X_test dataset ---\")\n",
        "print(X_test.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 7. Create and fit a DecisionTreeClassifier model ---\n",
        "# Use default parameters for the tree as none were specified\n",
        "dt_classifier = DecisionTreeClassifier(random_state=12345)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# --- 8. Generate predictions for the testing dataset ---\n",
        "predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "# --- 9. Add actual and predicted values to a new DataFrame and print first 10 records ---\n",
        "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
        "\n",
        "# Sort the index to align actuals with predictions (train_test_split shuffles by default)\n",
        "results_df = results_df.sort_index()\n",
        "\n",
        "print(\"--- First 10 records of Actual vs. Predicted values ---\")\n",
        "print(results_df.head(10))\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 10. Analyze the first 10 records ---\n",
        "# Count inaccuracies in the first 10 records: where Actual != Predicted\n",
        "inaccuracies_first_10 = (results_df.head(10)['Actual'] != results_df.head(10)['Predicted']).sum()\n",
        "print(f\"Number of inaccurate records in the first 10 predictions: {inaccuracies_first_10}\\n\")\n",
        "\n",
        "# --- 11. Count students currently active but predicted to quit (False Negatives) ---\n",
        "# Active means Actual == 1 (IN_SCHOOL_FLAG), predicted to quit means Predicted == 0\n",
        "false_negatives = ((results_df['Actual'] == 1) & (results_df['Predicted'] == 0)).sum()\n",
        "print(f\"Number of students currently active but predicted to quit (False Negatives): {false_negatives}\\n\")\n",
        "\n",
        "\n",
        "# --- 12. Generate accuracy, precision, recall, and f1 scores for active students (class 1) ---\n",
        "# Note: Sklearn metrics functions calculate scores for binary/multiclass classification.\n",
        "# For scores specific to class '1' (active students), we use the 'pos_label=1' and 'average=binary' parameters.\n",
        "\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "prec = precision_score(y_test, predictions, pos_label=1, average='binary')\n",
        "rec = recall_score(y_test, predictions, pos_label=1, average='binary')\n",
        "f1 = f1_score(y_test, predictions, pos_label=1, average='binary')\n",
        "\n",
        "print(f\"Accuracy Score: {acc}\")\n",
        "print(f\"Precision (for active students): {prec}\")\n",
        "print(f\"Recall (for active students): {rec}\")\n",
        "print(f\"F1 Score (for active students): {f1}\\n\")\n",
        "\n",
        "# --- 13. Determine the most important feature ---\n",
        "# Get feature importances from the fitted model\n",
        "feature_importances = pd.Series(dt_classifier.feature_importances_, index=X_train.columns)\n",
        "\n",
        "# Find the feature with the highest importance\n",
        "most_important_feature = feature_importances.idxmax()\n",
        "# Get the importance value for printing if needed\n",
        "# max_importance_value = feature_importances.max()\n",
        "\n",
        "print(f\"The most important feature is: {most_important_feature}\\n\")"
      ],
      "metadata": {
        "id": "UQNx85xnrnpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}