{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Checkpoint_Text_Analytics.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oHEgjpPfROOJ"},"source":["### READ ME\n","\n","Use the code blocks below to answer each question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Le-kBTguRIGI","executionInfo":{"elapsed":21384,"status":"ok","timestamp":1636064187879,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"},"user_tz":360},"outputId":"abf81ea8-a3c7-429a-d5c8-7245d374d530"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"rtSZVc6QRRsw","outputId":"7cc9a2bb-c169-4381-a74a-d8cbde644333"},"source":["# Question 0: Create a DataFrame with three rows and four columns. Name the \n","# columns 'Col1', 'Col2', 'Col3', 'Col4'. Create an index for the DataFrame\n","# and give the rows the index values of 'Row1', 'Row2', 'Row3'. Place a value\n","# in each column equal to the {ColumnName/RowName}. e.g. Col1/Row1. Print\n","# the entire DataFrame.\n","\n","import pandas as pd\n","\n","df = pd.DataFrame(columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3'])\n","\n","for col in df:\n","  for i, value in df[col].items():\n","    df.at[i, col] = f'{i}/{col}'\n","\n","df"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Col1</th>\n","      <th>Col2</th>\n","      <th>Col3</th>\n","      <th>Col4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Row1</th>\n","      <td>Row1/Col1</td>\n","      <td>Row1/Col2</td>\n","      <td>Row1/Col3</td>\n","      <td>Row1/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row2</th>\n","      <td>Row2/Col1</td>\n","      <td>Row2/Col2</td>\n","      <td>Row2/Col3</td>\n","      <td>Row2/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row3</th>\n","      <td>Row3/Col1</td>\n","      <td>Row3/Col2</td>\n","      <td>Row3/Col3</td>\n","      <td>Row3/Col4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Col1       Col2       Col3       Col4\n","Row1  Row1/Col1  Row1/Col2  Row1/Col3  Row1/Col4\n","Row2  Row2/Col1  Row2/Col2  Row2/Col3  Row2/Col4\n","Row3  Row3/Col1  Row3/Col2  Row3/Col3  Row3/Col4"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"IvltDJj6SKVW"},"source":["# Question 1: Install all necessary packages here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKH0Gc06Y6lz"},"source":["# Question 2: Import all necessary packages here. In addition, download\n","# the stopwords package from the nltk.corpus package. Set the stopwords\n","# list to the english version. Then, extend the stop words to include, \n","# 'from', 'subject', and 'co'. You will be asked later to come back to\n","# this cell to add more stop words to this list.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpLv8BdIRqNh"},"source":["# Question 3: Import the csv that is available that was provided with this\n","# assignment. Print the first five records and the number of records in \n","# this dataset in the output. \n","\n","# How many records are there?\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-PpJ4TTZ0T8"},"source":["# Question 4: Remove line breaks, single quotes, double quotes, email \n","# addresses, and tokenize each string. Convert each tweet to a list\n","# of cleaned words and add to a master list. Print out the first five\n","# cleaned tweets in the list.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmzD8HyrcKw_"},"source":["# Question 5: Build bigram and trigram models. Remove Stopwords, form \n","# Bigrams, Trigrams and perform Lemmatization. Use a threshold of 100 and \n","# a min_count of 5. Print the results of the first three clean tweets just\n","# before being lemmatized and after being lemmatized.\n","\n","# What does lemmatization do?\n","# ANSWER: Lemmitization is the process of converting a word to its base form\n","\n","# What's the difference in length of the first tweet before and after being lemmatized?\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbK6I3A3c0zs"},"source":["# Question 6: Create a dictionary and courpus and build your LDA \n","# model using 4 topics. Set the random_state to 12345. Set the\n","# chuncksize to 20, passes to 10, and per_word_topics to True. Do not\n","# set or adjust any other parameters (even if the example in the \n","# book does). Print out the topic weights for the 10 most important\n","# words in each topic.\n","\n","# What weight does the term \"autism\" have on Topic 0?\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uCtwz8sCNtB"},"source":["# Question 7: Generate LDA models for n = 3 through 9 topics and compare their perplexity \n","# and coherence scores. Keep all other parameter settings used in the prior question.\n","\n","# What are the values for perplexity and coherence of a\n","# model with n=4 topics?\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q__dOXw3CbhY"},"source":["# Question 8: Visualize results of comparing the perplexity/coherence from the previous\n","# question. \n","\n","# How many topics gives you the greatest difference?\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3CtjbhygVhr"},"source":["# Question 9: Generate new features (one for each topic) and then generate a \n","# topic score for every document. Nine topics will give us results with \n","# underrepresented and uneven topics, so for now let's use five topics. \n","# Keep all other parameter settings used in the prior question.\n","\n","# What is the dominant topic score of topic_1 for the first tweet \n","# (tweet_id 1440484799970304000) in your dataset?\n","# Note: Answer this question before eliminating words in question 12\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNoYEWU0h76X"},"source":["# Question 10: Create a wordcloud of Top N words in each topic. Copy the \n","# parameter settings for the WordCloud object that are used in the book.\n","\n","# What word appears in every word cloud?\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX_CvHFai9JZ"},"source":["# Question 11:\n","# Create a bar chart of word counts for all five topics. Plot Word Count and Weights\n","# of Topic Keywords. Which of the words below should be added to the stop words list?\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sj98oGIUmklT"},"source":["# Question 13:\n","# Visualize the number of documents/tweets attributed to each topic is through\n","# a t-distributed Stochastic Neighbor Embedding (SNE) chart. \n","\n","# Based on this chart, does it appear that every tweet was properly assigned \n","# to the most appropriate topic?\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yApDHh8lmrBf"},"source":["# Question 14:\n","# Print out an interactive visualization with pyLDAvis.\n","\n","# Which topic appears to be most related to needing help and support?\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjiZpyg0P4ch"},"source":[""],"execution_count":null,"outputs":[]}]}